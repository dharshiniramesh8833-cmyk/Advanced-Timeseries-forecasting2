This project focuses on advanced multivariate time series forecasting using a dataset containing 8 features and 1200 time steps. The dataset displays complex patterns such as long-term and short-term seasonality, nonlinear behavior, trend components, and random noise, making it suitable for evaluating deep learning forecasting models. Two predictive models were developed: a simple Transformer encoder model and a baseline LSTM model. The data was standardized and processed using a sliding-window approach, where a sequence of 50 past time steps was used to predict the next value. Both models were trained using the Adam optimizer and MSE loss. Evaluation metrics such as MSE, RMSE, and MAE were calculated, and visualizations of the dataset and prediction performance were included. Results showed that the Transformer model produced more accurate and stable forecasts than the LSTM baseline, demonstrating its strength in capturing long-range temporal dependencies. Overall, the project successfully illustrates modern forecasting techniques and highlights the effectiveness of attention-based models for complex time-series prediction.
